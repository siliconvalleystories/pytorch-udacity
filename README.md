# pytorch-udacity
1. Fashion_MNIST_with_validation_and_dropout_regularization.ipynb - Implements a deep neural network(not a CNN), plots training, test loss and accuracy and shows how training loss goes down with iterations but test loss doesnt showing high variance. Implements dropout regularization to solve the variance problem and the test loss also goes down with the training loss as the iterations increase showing that the NN doesnt overfit. 
2. cats_vs_dogs_saved_draft.ipynb - transfer learning, uses a pre-trained densenet model and adds two FC layers on top of it to decide between cats and dogs. Plots the training loss with the number of iterations and implements mini-batch gradient descent, code can handle both GPU and non-GPU training.
3. cifar_cnn.ipynb - splits the training data into train and validation sets, trains a CNN with conv2d, maxpooling and FC layers, plots the losses on the training and the validation sets and chooses the model with the lowest validation loss.
4. cnn_visualizations.ipynb - demonstrates how to create a CNN with planned weights for the filters, how to return both the pre and post activation scores from the conv layer, visualizes both the images and the filters thus helping to understand how the vertical and the horizontal edge detection happens based on the kind of filter being chosen. A real CNN will off course tune the weights of the filters on its own, but this is a great demonstration using pre-planned weights to see the outputs
   of the intermediate hidden layers.
5. 
